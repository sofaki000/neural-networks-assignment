https://scikit-learn.org/stable/modules/neighbors.html

11/7:1,17min

11/8
links used:
https://github.com/konradmaciejczyk/star-type-classification -> implementations
https://machinelearningmastery.com/nearest-shrunken-centroids-with-python/#:~:text=Nearest%20Centroids%20is%20a%20classification,make%20predictions%20for%20new%20examples.

convolutional theory:
https://www.learndatasci.com/tutorials/convolutional-neural-networks-image-classification/
2h,1.30 = 3.3h


11/10
45min+45min


11/11
time: 1h,1h,45min,1h
Samplers : https://towardsdatascience.com/pytorch-basics-sampling-samplers-2a0f29f0bf2a
https://pytorch.org/docs/stable/optim.html#how-to-use-an-optimizer
https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD
https://analyticsindiamag.com/ultimate-guide-to-pytorch-optimizers/
https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab
https://mlfromscratch.com/neural-networks-explained/#/
https://mlfromscratch.com/optimizers-explained/#stochastic-gradient-descent
https://programmathically.com/weight-decay-in-neural-networks/
https://mlfromscratch.com/optimizers-explained/#/
https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1


12/11
times: 1h, 50m,15m,50=3h
https://github.com/timgaripov/swa
Averaging Weights Leads to Wider Optima and Better Generalization,Pavel Izmailov

13/11
time: 45m,47m ,1.15,40m = 3h 45m sto knn
k centroi: 30m,35m, general:43m = 5.30

Source: https://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/#introduction
Source: https://pytorch.org/docs/stable/optim.html#how-to-use-an-optimizer
https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learn -> check their cnn
https://www.datacamp.com/tutorial/principal-component-analysis-in-python
https://builtin.com/data-science/step-step-explanation-principal-component-analysis
https://www.datacamp.com/tutorial/feature-selection-python
https://en.wikipedia.org/wiki/Cross-validation_(statistics)

TODO:
1. mhpws to encoding den einai kalo kai thelei kanena me embedding?opws onehotencoding?
TSEKARE DIFFERENT ENCODINGS!!